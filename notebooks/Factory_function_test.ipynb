{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02057cba",
   "metadata": {},
   "source": [
    "Factory function for using trace for predict out of sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ded4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.11.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Gil\\anaconda\\envs\\pymc3_cellpose\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "F:\\Gil\\anaconda\\envs\\pymc3_cellpose\\lib\\site-packages\\skimage\\viewer\\utils\\__init__.py:1: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import dcc \n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageEnhance, ImageDraw,ImageFont\n",
    "import seaborn as sns\n",
    "#sns.set()\n",
    "import arviz as az\n",
    "import pymc3 as pm\n",
    "print(pm.__version__)\n",
    "import theano.tensor as tt\n",
    "import patsy\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import plotnine\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotnine \n",
    "from plotnine.data import economics \n",
    "from plotnine import * \n",
    "import plotly.express as px\n",
    "\n",
    "from skimage import measure, restoration,morphology\n",
    "from skimage import io, filters, measure, color, img_as_ubyte\n",
    "from skimage.draw import disk\n",
    "from skimage import measure, restoration,morphology\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "os.chdir(r'F:\\HAB_2\\PrinzScreen\\training_classfication')\n",
    "from utils import AIPS_cellpose as AC\n",
    "from utils import AIPS_file_display as AFD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5621847f",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "RANDOM_SEED = 58\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980623ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 688.55it/s]\n"
     ]
    }
   ],
   "source": [
    "path = r'E:\\Elliot\\classification\\data\\beyes_table'\n",
    "tabel_samp = pd.read_csv(os.path.join(path,'SG_granularty_table_80opening_signale_reduction_25sample.csv'))\n",
    "tabel_samp.head(1)\n",
    "def add_class_randomise_and_pm_reconst(table_input, obser_number=10,show_class = False, vec=None):\n",
    "    from sklearn import preprocessing\n",
    "    tabel_5samp = table_input\n",
    "    image_group =  tabel_5samp['image_name'].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # encoding\n",
    "    # class_name_encoded=le.fit_transform(class_name).tolist()\n",
    "    image_group_encoded=le.fit_transform(image_group).tolist()\n",
    "\n",
    "\n",
    "    # adding a uneaqe class column \n",
    "    image_group =  tabel_5samp['image_name'].values.tolist()\n",
    "    image_group_cls = []\n",
    "    for i,img in enumerate(image_group):\n",
    "        image_group_cls.append(img.split('_')[0]+ '_'+str(image_group_encoded[i]))\n",
    "    image_group_cls    \n",
    "    tabel_5samp['image_name_cls'] = image_group_cls\n",
    "\n",
    "     # data sorting\n",
    "    un_name = np.unique(tabel_5samp['image_name_cls']).tolist()\n",
    "    import random\n",
    "    random.shuffle(un_name)\n",
    "    un_name\n",
    "\n",
    "    def restructure_table(table, unique_name):\n",
    "        table_temp = table.loc[lambda x: (x['image_name_cls'] == unique_name),:]\n",
    "        return table_temp\n",
    "    table_train = restructure_table(tabel_5samp, un_name[0])\n",
    "    for i in tqdm(range(1,obser_number)):\n",
    "        table_temp = restructure_table(tabel_5samp, un_name[i])\n",
    "        table_train = pd.concat((table_train,table_temp))\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    table_sel = table_train\n",
    "    # class_name =  table_sel['class'].values\n",
    "    image_group =  table_sel['image_name'].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # encoding\n",
    "    # class_name_encoded=le.fit_transform(class_name).tolist()\n",
    "    image_group_encoded=le.fit_transform(image_group).tolist()\n",
    "    table_dict={'image_signal':table_sel.open_image_signal.values.tolist(),\n",
    "                'raius_list':table_sel.radius_list.values.tolist(),\n",
    "                'image_group':image_group_encoded}\n",
    "    table = pd.DataFrame(table_dict)\n",
    "    table['image_group'] = pd.Categorical(table['image_group'], ordered=False)\n",
    "\n",
    "    image_group =  table_sel['image_name'].values.tolist()\n",
    "    image_group_cls = []\n",
    "    for i,img in enumerate(image_group):\n",
    "        if show_class:\n",
    "            image_group_cls.append(img.split('_')[0])\n",
    "        else:\n",
    "            image_group_cls.append(img.split('_')[0]+ '_'+str(image_group_encoded[i]))\n",
    "    image_group_cls    \n",
    "    table['image_name_cls'] = image_group_cls\n",
    "    table_vec_1 = table.loc[table['raius_list'].isin(vec),:]\n",
    "    return table_vec_1\n",
    "\n",
    "vec_2 = np.linspace(1,79,20,endpoint=True,dtype=int )    \n",
    "table_draft = add_class_randomise_and_pm_reconst(tabel_samp,obser_number=40, show_class = True, vec = vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7670879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:800\n",
      "opening_opr:800\n",
      "signal:800\n"
     ]
    }
   ],
   "source": [
    "a = np.array(table_draft['image_group'])\n",
    "_, idx = np.unique(a, return_index=True)\n",
    "id__ = np.array(np.repeat(a[np.sort(idx)],20))\n",
    "opening_opr__ = np.array(table_draft.raius_list.values) # 40*5\n",
    "signal__ = np.array(table_draft.image_signal.values) # 40*5\n",
    "id_paramaters__ = 40\n",
    "\n",
    "\n",
    "print('id:{}'.format(len(id__))) #4000\n",
    "print('opening_opr:{}'.format(len(opening_opr__))) # 40*5\n",
    "print('signal:{}'.format(len(signal__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0935b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_factory(x,y, z, sig):\n",
    "    with pm.Model() as model:\n",
    "        a = pm.Normal('a',50,20,shape= y)\n",
    "        b = pm.Exponential('b',0.3,shape= y)\n",
    "        c = pm.Normal('c',5,10,shape= y)\n",
    "    \n",
    "        mu = a[z] + c[z] * tt.exp(-b[z] * x)  # linear model\n",
    "        sigma_within = pm.Exponential(\"sigma_within\", 1.0)  # prior stddev within image\n",
    "        signal = pm.Normal(\"signal\", mu=mu, sigma=sigma_within, observed=sig)  # likelihood\n",
    "    \n",
    "        #trace_simple_model_decay = pm.sample(4000, tune=4000, target_accept=0.9)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bef25e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Gil\\anaconda\\envs\\pymc3_cellpose\\lib\\site-packages\\deprecat\\classic.py:215: FutureWarning: In v4.0, pm.sample will return an `arviz.InferenceData` object instead of a `MultiTrace` by default. You can pass return_inferencedata=True or return_inferencedata=False to be safe and silence this warning.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [sigma_within, c, b, a]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='32000' class='' max='32000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32000/32000 04:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 4_000 tune and 4_000 draw iterations (16_000 + 16_000 draws total) took 274 seconds.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    }
   ],
   "source": [
    "with model_factory(x=opening_opr__,\n",
    "                   y=id_paramaters__,\n",
    "                   z=id__,\n",
    "                   sig=signal__) as train_model:\n",
    "    train_trace = pm.sample(4000, tune=4000, target_accept=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "168d8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 501.32it/s]\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "vec_2 = np.linspace(1,79,20,endpoint=True,dtype=int )    \n",
    "table_test = add_class_randomise_and_pm_reconst(tabel_samp,obser_number=3, show_class = True, vec = vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a966ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:60\n",
      "opening_opr:60\n",
      "signal:60\n"
     ]
    }
   ],
   "source": [
    "a = np.array(table_test['image_group'])\n",
    "_, idx = np.unique(a, return_index=True)\n",
    "id_test = np.array(np.repeat(a[np.sort(idx)],20))\n",
    "opening_opr__test = np.array(table_test.raius_list.values) # 40*5\n",
    "signal__test = np.array(table_test.image_signal.values) # 40*5\n",
    "id_paramaters__test = 3\n",
    "print('id:{}'.format(len(id_test))) #4000\n",
    "print('opening_opr:{}'.format(len(opening_opr__test))) # 40*5\n",
    "print('signal:{}'.format(len(signal__test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5dbf643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='16000' class='' max='16000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [16000/16000 01:20<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with model_factory(x=opening_opr__test,\n",
    "                   y=id_paramaters__test,\n",
    "                   z=id_test,\n",
    "                   sig=signal__test) as test_model:\n",
    "    # We first have to extract the learnt global effect from the train_trace\n",
    "    df = pm.trace_to_dataframe(train_trace,\n",
    "                               varnames=[\"a\",\"b\",\"c\",'sigma_within'],\n",
    "                               include_transformed=True)\n",
    "    # We have to supply the samples kwarg because it cannot be inferred if the\n",
    "    # input trace is not a MultiTrace instance\n",
    "    p_post = pm.sample_posterior_predictive(trace=df.to_dict('records'),var_names=[\"a\",\"b\",\"c\",'sigma_within',\"signal\"],\n",
    "                                         samples=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "033b0694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>a_sd</th>\n",
       "      <th>b_sd</th>\n",
       "      <th>c_sd</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.004799</td>\n",
       "      <td>3.350941</td>\n",
       "      <td>5.049750</td>\n",
       "      <td>19.999803</td>\n",
       "      <td>3.365323</td>\n",
       "      <td>9.918176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.212436</td>\n",
       "      <td>3.339356</td>\n",
       "      <td>4.874096</td>\n",
       "      <td>20.012609</td>\n",
       "      <td>3.315280</td>\n",
       "      <td>9.969463</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.028955</td>\n",
       "      <td>3.331160</td>\n",
       "      <td>4.986351</td>\n",
       "      <td>19.979249</td>\n",
       "      <td>3.343222</td>\n",
       "      <td>10.004150</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           a         b         c       a_sd      b_sd       c_sd  Image\n",
       "0  50.004799  3.350941  5.049750  19.999803  3.365323   9.918176      0\n",
       "1  50.212436  3.339356  4.874096  20.012609  3.315280   9.969463      1\n",
       "2  50.028955  3.331160  4.986351  19.979249  3.343222  10.004150      2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.mean(p_post['b'],0)\n",
    "b_sd = np.std(p_post['b'],0)\n",
    "c = np.mean(p_post['c'],0)\n",
    "c_sd = np.std(p_post['c'],0)\n",
    "a = np.mean(p_post['a'],0)\n",
    "a_sd = np.std(p_post['a'],0)\n",
    "uniqe_list_image_name = np.unique(table_test['image_group'])\n",
    "\n",
    "df_pred = pd.DataFrame({'a':a,'b':b,'c':c,'a_sd':a_sd,'b_sd':b_sd,\"c_sd\":c_sd,'Image':uniqe_list_image_name})\n",
    "df_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6aedfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pymc3_cellpose] *",
   "language": "python",
   "name": "conda-env-pymc3_cellpose-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
