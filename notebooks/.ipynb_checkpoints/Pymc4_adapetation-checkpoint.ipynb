{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02057cba",
   "metadata": {},
   "source": [
    "PYMC4 adaptation of mixed model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ded4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#pd.set_option('display.max_columns', 500)\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import dcc \n",
    "from dash import html\n",
    "from dash.dependencies import Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#sns.set()\n",
    "import arviz as az\n",
    "import theano.tensor as tt\n",
    "import patsy\n",
    "\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import random\n",
    "import plotnine\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotnine \n",
    "from plotnine.data import economics \n",
    "from plotnine import * \n",
    "import plotly.express as px\n",
    "\n",
    "from skimage import measure, restoration,morphology\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5621847f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on PyMC v4.0.1\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "import theano.tensor as tt\n",
    "import pymc as pm\n",
    "import xarray as xr\n",
    "import aesara\n",
    "import aesara.tensor as at\n",
    "\n",
    "from pymc import HalfCauchy, Model, Normal, sample\n",
    "\n",
    "print(f\"Running on PyMC v{pm.__version__}\")\n",
    "\n",
    "az.style.use(\"arviz-darkgrid\")\n",
    "\n",
    "RANDOM_SEED = 58\n",
    "rng = np.random.default_rng(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "980623ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 39/39 [00:00<00:00, 514.53it/s]\n"
     ]
    }
   ],
   "source": [
    "path = r'E:\\Elliot\\classification\\data\\beyes_table'\n",
    "tabel_samp = pd.read_csv(os.path.join(path,'SG_granularty_table_80opening_signale_reduction_25sample.csv'))\n",
    "tabel_samp.head(1)\n",
    "def add_class_randomise_and_pm_reconst(table_input, obser_number=10,show_class = False, vec=None):\n",
    "    from sklearn import preprocessing\n",
    "    tabel_5samp = table_input\n",
    "    image_group =  tabel_5samp['image_name'].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # encoding\n",
    "    # class_name_encoded=le.fit_transform(class_name).tolist()\n",
    "    image_group_encoded=le.fit_transform(image_group).tolist()\n",
    "\n",
    "\n",
    "    # adding a uneaqe class column \n",
    "    image_group =  tabel_5samp['image_name'].values.tolist()\n",
    "    image_group_cls = []\n",
    "    for i,img in enumerate(image_group):\n",
    "        image_group_cls.append(img.split('_')[0]+ '_'+str(image_group_encoded[i]))\n",
    "    image_group_cls    \n",
    "    tabel_5samp['image_name_cls'] = image_group_cls\n",
    "\n",
    "     # data sorting\n",
    "    un_name = np.unique(tabel_5samp['image_name_cls']).tolist()\n",
    "    import random\n",
    "    random.shuffle(un_name)\n",
    "    un_name\n",
    "\n",
    "    def restructure_table(table, unique_name):\n",
    "        table_temp = table.loc[lambda x: (x['image_name_cls'] == unique_name),:]\n",
    "        return table_temp\n",
    "    table_train = restructure_table(tabel_5samp, un_name[0])\n",
    "    for i in tqdm(range(1,obser_number)):\n",
    "        table_temp = restructure_table(tabel_5samp, un_name[i])\n",
    "        table_train = pd.concat((table_train,table_temp))\n",
    "\n",
    "    from sklearn import preprocessing\n",
    "    table_sel = table_train\n",
    "    # class_name =  table_sel['class'].values\n",
    "    image_group =  table_sel['image_name'].values\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    # encoding\n",
    "    # class_name_encoded=le.fit_transform(class_name).tolist()\n",
    "    image_group_encoded=le.fit_transform(image_group).tolist()\n",
    "    table_dict={'image_signal':table_sel.open_image_signal.values.tolist(),\n",
    "                'raius_list':table_sel.radius_list.values.tolist(),\n",
    "                'image_group':image_group_encoded}\n",
    "    table = pd.DataFrame(table_dict)\n",
    "    table['image_group'] = pd.Categorical(table['image_group'], ordered=False)\n",
    "\n",
    "    image_group =  table_sel['image_name'].values.tolist()\n",
    "    image_group_cls = []\n",
    "    for i,img in enumerate(image_group):\n",
    "        if show_class:\n",
    "            image_group_cls.append(img.split('_')[0])\n",
    "        else:\n",
    "            image_group_cls.append(img.split('_')[0]+ '_'+str(image_group_encoded[i]))\n",
    "    image_group_cls    \n",
    "    table['image_name_cls'] = image_group_cls\n",
    "    table_vec_1 = table.loc[table['raius_list'].isin(vec),:]\n",
    "    return table_vec_1\n",
    "\n",
    "vec_2 = np.linspace(1,79,20,endpoint=True,dtype=int )    \n",
    "table_draft = add_class_randomise_and_pm_reconst(tabel_samp,obser_number=40, show_class = True, vec = vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7670879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:800\n",
      "opening_opr:800\n",
      "signal:800\n"
     ]
    }
   ],
   "source": [
    "a = np.array(table_draft['image_group'])\n",
    "_, idx = np.unique(a, return_index=True)\n",
    "id__ = np.array(np.repeat(a[np.sort(idx)],20))\n",
    "opening_opr__ = np.array(table_draft.raius_list.values) # 40*5\n",
    "signal__ = np.array(table_draft.image_signal.values) # 40*5\n",
    "id_paramaters__ = 40\n",
    "\n",
    "\n",
    "print('id:{}'.format(len(id__))) #4000\n",
    "print('opening_opr:{}'.format(len(opening_opr__))) # 40*5\n",
    "print('signal:{}'.format(len(signal__)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e8f932",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The `shape` parameter must be a tuple, TensorVariable, int or list. Actual: <class 'aesara.tensor.sharedvar.TensorSharedVariable'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_312\\3977623959.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msignal_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"signal_\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msignal__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mid_paramaters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExponential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mid_paramaters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mid_paramaters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Gil\\anaconda\\envs\\pymc4_cellpose\\lib\\site-packages\\pymc\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__new__\u001b[1;34m(cls, name, rng, dims, initval, observed, total_size, transform, *args, **kwargs)\u001b[0m\n\u001b[0;32m    262\u001b[0m         \u001b[1;31m# a shape by which the created RV may need to be resized.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m         rv_out, dims, observed, resize_shape = _make_rv_and_resize_shape(\n\u001b[1;32m--> 264\u001b[1;33m             \u001b[0mcls\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobserved\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobserved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         )\n\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Gil\\anaconda\\envs\\pymc4_cellpose\\lib\\site-packages\\pymc\\distributions\\distribution.py\u001b[0m in \u001b[0;36m_make_rv_and_resize_shape\u001b[1;34m(cls, dims, model, observed, args, **kwargs)\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;31m# Create the RV without dims information, because that's not something tracked at the Aesara level.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;31m# If necessary we'll later replicate to a different size implied by already known dims.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m     \u001b[0mrv_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m     \u001b[0mndim_actual\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrv_out\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[0mresize_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Gil\\anaconda\\envs\\pymc4_cellpose\\lib\\site-packages\\pymc\\distributions\\continuous.py\u001b[0m in \u001b[0;36mdist\u001b[1;34m(cls, mu, sigma, tau, no_assert, **kwargs)\u001b[0m\n\u001b[0;32m    553\u001b[0m             \u001b[0massert_negative_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sigma\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Normal\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmoment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Gil\\anaconda\\envs\\pymc4_cellpose\\lib\\site-packages\\pymc\\distributions\\distribution.py\u001b[0m in \u001b[0;36mdist\u001b[1;34m(cls, dist_params, shape, **kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m             )\n\u001b[0;32m    342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m         \u001b[0mshape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    344\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Gil\\anaconda\\envs\\pymc4_cellpose\\lib\\site-packages\\pymc\\distributions\\shape_utils.py\u001b[0m in \u001b[0;36mconvert_shape\u001b[1;34m(shape)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         raise ValueError(\n\u001b[1;32m--> 469\u001b[1;33m             \u001b[1;34mf\"The `shape` parameter must be a tuple, TensorVariable, int or list. Actual: {type(shape)}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    470\u001b[0m         )\n\u001b[0;32m    471\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEllipsis\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The `shape` parameter must be a tuple, TensorVariable, int or list. Actual: <class 'aesara.tensor.sharedvar.TensorSharedVariable'>"
     ]
    }
   ],
   "source": [
    "with pm.Model() as simple_model_decay:\n",
    "    id_paramaters = pm.Data(\"id_paramaters\",id_paramaters__)\n",
    "    id_ = pm.Data(\"id_\",id__)\n",
    "    opening_opr = pm.Data(\"opening_opr\",opening_opr__)\n",
    "    signal_ = pm.Data(\"signal_\",signal__)\n",
    "    \n",
    "    a = pm.Normal('a',50,20,shape= id_paramaters__)\n",
    "    b = pm.Exponential('b',0.3,shape= id_paramaters__)\n",
    "    c = pm.Normal('c',5,10,shape= id_paramaters__)\n",
    "    \n",
    "    mu = a[id__] + c[id__] * at.exp(-b[id__] * opening_opr__)  # linear model\n",
    "    sigma_within = pm.Exponential(\"sigma_within\", 1.0)  # prior stddev within image\n",
    "    signal = pm.Normal(\"signal\", mu=mu, sigma=sigma_within, observed=signal__)  # likelihood\n",
    "    \n",
    "    trace_simple_model_decay = pm.sample(4000, tune=4000, target_accept=0.9)  # likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0935b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_factory(x,y, z, sig):\n",
    "    with pm.Model() as model:\n",
    "        a = pm.Normal('a',50,20,shape= y)\n",
    "        b = pm.Exponential('b',0.3,shape= y)\n",
    "        c = pm.Normal('c',5,10,shape= y)\n",
    "    \n",
    "        mu = a[z] + c[z] * at.exp(-b[z] * x)  # linear model\n",
    "        sigma_within = pm.Exponential(\"sigma_within\", 1.0)  # prior stddev within image\n",
    "        signal = pm.Normal(\"signal\", mu=mu, sigma=sigma_within, observed=sig)  # likelihood\n",
    "    \n",
    "        trace_simple_model_decay = pm.sample(4000, tune=4000, target_accept=0.9)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bef25e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b, c, sigma_within]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='32000' class='' max='32000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32000/32000 04:45<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 4_000 tune and 4_000 draw iterations (16_000 + 16_000 draws total) took 315 seconds.\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b, c, sigma_within]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='8000' class='' max='8000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [8000/8000 01:04<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 94 seconds.\n"
     ]
    }
   ],
   "source": [
    "with model_factory(x=opening_opr__,\n",
    "                   y=id_paramaters__,\n",
    "                   z=id__,\n",
    "                   sig=signal__) as train_model:\n",
    "    train_trace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168d8285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 200.54it/s]\n"
     ]
    }
   ],
   "source": [
    "# new data\n",
    "vec_2 = np.linspace(1,79,20,endpoint=True,dtype=int )    \n",
    "table_test = add_class_randomise_and_pm_reconst(tabel_samp,obser_number=3, show_class = True, vec = vec_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a966ce0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id:60\n",
      "opening_opr:60\n",
      "signal:60\n"
     ]
    }
   ],
   "source": [
    "a = np.array(table_test['image_group'])\n",
    "_, idx = np.unique(a, return_index=True)\n",
    "id_test = np.array(np.repeat(a[np.sort(idx)],20))\n",
    "opening_opr__test = np.array(table_test.raius_list.values) # 40*5\n",
    "signal__test = np.array(table_test.image_signal.values) # 40*5\n",
    "id_paramaters__test = 3\n",
    "print('id:{}'.format(len(id_test))) #4000\n",
    "print('opening_opr:{}'.format(len(opening_opr__test))) # 40*5\n",
    "print('signal:{}'.format(len(signal__test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b5dbf643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, b, c, sigma_within]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='32000' class='' max='32000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [32000/32000 01:25<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 4_000 tune and 4_000 draw iterations (16_000 + 16_000 draws total) took 113 seconds.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pymc' has no attribute 'trace_to_dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_312\\79699945.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                    sig=signal__test) as test_model:\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# We first have to extract the learnt global effect from the train_trace\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     df = pm.trace_to_dataframe(train_trace,\n\u001b[0m\u001b[0;32m      7\u001b[0m                                \u001b[0mvarnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"a\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'sigma_within'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"signal\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                                include_transformed=True)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pymc' has no attribute 'trace_to_dataframe'"
     ]
    }
   ],
   "source": [
    "with model_factory(x=opening_opr__test,\n",
    "                   y=id_paramaters__test,\n",
    "                   z=id_test,\n",
    "                   sig=signal__test) as test_model:\n",
    "    # We first have to extract the learnt global effect from the train_trace\n",
    "    df = pm.trace_to_dataframe(train_trace,\n",
    "                               varnames=[\"a\",\"b\",\"c\",'sigma_within',\"signal\"],\n",
    "                               include_transformed=True)\n",
    "    # We have to supply the samples kwarg because it cannot be inferred if the\n",
    "    # input trace is not a MultiTrace instance\n",
    "    ppc = pm.sample_posterior_predictive(trace=df.to_dict('records'),\n",
    "                                         samples=len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "033b0694",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ppc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_312\\1008619847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mppc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ppc' is not defined"
     ]
    }
   ],
   "source": [
    "ppc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6aedfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pymc4_cellpose] *",
   "language": "python",
   "name": "conda-env-pymc4_cellpose-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
